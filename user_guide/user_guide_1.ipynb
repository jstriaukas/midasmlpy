{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import midasmlpy.date_functions as datef # used to handle different frequencies of data and to create lags\n",
    "import midasmlpy.sparse_group_lasso as sgl # used to run the sparse group lasso and related functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# load data from xlsx files and create a dataframe\n",
    "Predictors = pd.read_excel(os.path.abspath('predictors-monthly.xlsx')).to_numpy()\n",
    "Target = pd.read_excel(os.path.abspath('recessions-quarterly.xlsx')).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into dates and data tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y data and X and Y dates can also be defined as they are the same for all iterations\n",
    "Y_date = Target[:,0]\n",
    "Y = Target[:,1]\n",
    "X_date = Predictors[:,0]\n",
    "X = Predictors[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform data using functions from data_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define variables ued in transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lag variables\n",
    "x_lags = 3\n",
    "y_lags = 0\n",
    "horizon = 0\n",
    "\n",
    "# Legendre matrix\n",
    "degree = 4 # 3 degrees + polynomial 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call data transformation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = datef.data_transform(Y, Y_date, X, X_date, x_lags, y_lags, horizon, degree=degree, standardize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sgLasso binomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The performance at different values of alpha are:\n",
      "{np.float64(1.0): np.float64(0.50489), np.float64(0.9): np.float64(0.50489), np.float64(0.8): np.float64(0.50163), np.float64(0.7): np.float64(0.5183), np.float64(0.6): np.float64(0.50924), np.float64(0.5): np.float64(0.51848), np.float64(0.3999999999999999): np.float64(0.51413), np.float64(0.29999999999999993): np.float64(0.50996), np.float64(0.19999999999999996): np.float64(0.5), np.float64(0.09999999999999998): np.float64(0.50163), np.float64(0.0): np.float64(0.50163)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = transformed_data['X_tilde']\n",
    "y = transformed_data['Y']\n",
    "\n",
    "# # Split x and y into a 80/20 train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "family = 'binomial'\n",
    "\n",
    "# Run the sparse group lasso\n",
    "model = sgl.best_model(x=X_train, y=y_train, group_size=degree, family=family, nlam=100, pmax=122, intr=False, k_folds=5, disp_flag=True, alpha_values=11, alpha=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The performance at different values of alpha are:\n",
      "{np.float64(0.175): np.float64(0.50163), np.float64(0.15): np.float64(0.50163), np.float64(0.125): np.float64(0.50163), np.float64(0.075): np.float64(0.50163), np.float64(0.05): np.float64(0.50163), np.float64(0.025): np.float64(0.50163)}\n"
     ]
    }
   ],
   "source": [
    "model_alpha_specified = sgl.best_model(x=X_train, y=y_train, group_size=degree, family=family, nlam=100, pmax=122, intr=False, k_folds=5, disp_flag=True, alpha_values=None, alpha=(0.175,0.15,0.125,0.075,0.05,0.025))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0    1    2    3    4    5    6    7    8    9   ...        90  \\\n",
      "1.00    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ... -0.044630   \n",
      "1.00    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ... -0.044630   \n",
      "1.00    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ... -0.044630   \n",
      "1.00    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ... -0.044630   \n",
      "1.00    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ... -0.044630   \n",
      "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...       ...   \n",
      "106.75  0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0  ... -0.001485   \n",
      "106.75  0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0  ... -0.001485   \n",
      "106.75  0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0  ... -0.001485   \n",
      "106.75  0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0  ... -0.001485   \n",
      "106.75  0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0 -0.0  ... -0.001485   \n",
      "\n",
      "              91        92        93        94        95        96        97  \\\n",
      "1.00   -0.045380 -0.046139 -0.046908 -0.047685 -0.048471 -0.049267 -0.050071   \n",
      "1.00   -0.045380 -0.046139 -0.046908 -0.047685 -0.048471 -0.049267 -0.050071   \n",
      "1.00   -0.045380 -0.046139 -0.046908 -0.047685 -0.048471 -0.049267 -0.050071   \n",
      "1.00   -0.045380 -0.046139 -0.046908 -0.047685 -0.048471 -0.049267 -0.050071   \n",
      "1.00   -0.045380 -0.046139 -0.046908 -0.047685 -0.048471 -0.049267 -0.050071   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "106.75 -0.001545 -0.001607 -0.001672 -0.001739 -0.001808 -0.001880 -0.001954   \n",
      "106.75 -0.001545 -0.001607 -0.001672 -0.001739 -0.001808 -0.001880 -0.001954   \n",
      "106.75 -0.001545 -0.001607 -0.001672 -0.001739 -0.001808 -0.001880 -0.001954   \n",
      "106.75 -0.001545 -0.001607 -0.001672 -0.001739 -0.001808 -0.001880 -0.001954   \n",
      "106.75 -0.001545 -0.001607 -0.001672 -0.001739 -0.001808 -0.001880 -0.001954   \n",
      "\n",
      "              98        99  \n",
      "1.00   -0.050884 -0.051708  \n",
      "1.00   -0.050884 -0.051708  \n",
      "1.00   -0.050884 -0.051708  \n",
      "1.00   -0.050884 -0.051708  \n",
      "1.00   -0.050884 -0.051708  \n",
      "...          ...       ...  \n",
      "106.75 -0.002030 -0.002108  \n",
      "106.75 -0.002030 -0.002108  \n",
      "106.75 -0.002030 -0.002108  \n",
      "106.75 -0.002030 -0.002108  \n",
      "106.75 -0.002030 -0.002108  \n",
      "\n",
      "[2386 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(model_alpha_specified['beta']).set_index(pd.DataFrame(model_alpha_specified['beta']).index / 4).loc[model_alpha_specified['beta']!=0]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 1 1 ... 1 1 1]\n",
      " [0 1 1 ... 1 1 1]\n",
      " ...\n",
      " [0 1 1 ... 1 1 1]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 1 ... 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "preds = sgl.predict_binomial(x=X_test, b0=model_alpha_specified['b0'], beta=model_alpha_specified['beta'])\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_alsparse': np.float64(0.175),\n",
       " 'best_performance': np.float64(0.5016304347826087),\n",
       " 'b0': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'beta': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " 'best_lambda': np.float64(0.0169907919957961),\n",
       " 'best_beta': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_alpha_specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.5),\n",
       " np.float64(0.41532258064516125),\n",
       " np.float64(0.41532258064516125),\n",
       " np.float64(0.41532258064516125),\n",
       " np.float64(0.41532258064516125),\n",
       " np.float64(0.4475806451612903),\n",
       " np.float64(0.4637096774193549),\n",
       " np.float64(0.4637096774193549),\n",
       " np.float64(0.4637096774193549),\n",
       " np.float64(0.41532258064516125),\n",
       " np.float64(0.6330645161290323),\n",
       " np.float64(0.6330645161290323),\n",
       " np.float64(0.6169354838709677),\n",
       " np.float64(0.6008064516129032),\n",
       " np.float64(0.6008064516129032),\n",
       " np.float64(0.6008064516129032),\n",
       " np.float64(0.5846774193548387),\n",
       " np.float64(0.5846774193548387),\n",
       " np.float64(0.5846774193548387),\n",
       " np.float64(0.5846774193548387),\n",
       " np.float64(0.5846774193548387),\n",
       " np.float64(0.6008064516129032),\n",
       " np.float64(0.6008064516129032),\n",
       " np.float64(0.6008064516129032),\n",
       " np.float64(0.5846774193548387),\n",
       " np.float64(0.5846774193548387),\n",
       " np.float64(0.5846774193548387),\n",
       " np.float64(0.5846774193548387),\n",
       " np.float64(0.5846774193548387),\n",
       " np.float64(0.6008064516129032),\n",
       " np.float64(0.6169354838709677),\n",
       " np.float64(0.6169354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7580645161290323),\n",
       " np.float64(0.7580645161290323),\n",
       " np.float64(0.7580645161290323),\n",
       " np.float64(0.7580645161290323),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677),\n",
       " np.float64(0.7419354838709677)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgl.evaluate_binomials(X_test, y_test, model_alpha_specified['b0'], model_alpha_specified['beta'], eval = 'auc', threshold=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
