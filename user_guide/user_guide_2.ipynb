{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import midasmlpy.date_functions as datef # used to handle different frequencies of data and to create lags\n",
    "import midasmlpy.sparse_group_lasso as sgl\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# load data from xlsx files and create a dataframe\n",
    "\n",
    "Predictors = pd.read_excel(os.path.abspath('predictors-monthly.xlsx')).to_numpy()\n",
    "Target = pd.read_excel(os.path.abspath('gdp-quarterly.xlsx')).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Timestamp('1980-01-01 00:00:00') 0.00141245089699638\n",
      "  -0.0011552922185345 ... 0.00903300474278623 -0.00604040201996625\n",
      "  21.0903]\n",
      " [Timestamp('1980-02-01 00:00:00') -0.00456617930994874\n",
      "  -0.00389234838978325 ... -0.0148620800568615 0.0140006758812898 22.2919]\n",
      " [Timestamp('1980-03-01 00:00:00') -0.00530077784951999\n",
      "  -0.00343020822286455 ... 0.000185183409865175 -0.00496429192770176\n",
      "  29.2535]\n",
      " ...\n",
      " [Timestamp('2023-08-01 00:00:00') 0.000748921515789647\n",
      "  0.00175864553192895 ... 0.0007155070429814 -0.00600931526191673 15.7822]\n",
      " [Timestamp('2023-09-01 00:00:00') -0.000509381619856697\n",
      "  0.000725495468836712 ... -0.00163704170406653 0.00331903172316572\n",
      "  15.0424]\n",
      " [Timestamp('2023-10-01 00:00:00') 0.00221083275208933\n",
      "  0.00309969441820179 ... -0.000859076321829022 -0.00445350854847071\n",
      "  19.0462]]\n"
     ]
    }
   ],
   "source": [
    "print(Predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into dates and data tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y data and X and Y dates can also be defined as they are the same for all iterations\n",
    "Y_date = Target[:,0]\n",
    "Y = Target[:,1]\n",
    "X_date = Predictors[:,0]\n",
    "X = Predictors[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform data using functions from data_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define variables ued in transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lag variables\n",
    "x_lags = 3\n",
    "y_lags = 0\n",
    "horizon = 0\n",
    "\n",
    "# Legendre matrix\n",
    "degree = 4 # 3 degrees + polynomial 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call data transformation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = datef.data_transform(Y, Y_date, X, X_date, x_lags, y_lags, horizon, degree=degree, standardize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Y': array([ -8.32783,  -0.4757 ,   7.39099,   7.76189,  -2.97534,   4.76156,\n",
      "        -4.38231,  -6.26336,   1.82056,  -1.532  ,   0.16   ,   5.23673,\n",
      "         9.00007,   7.91695,   8.25888,   7.74372,   6.85202,   3.83757,\n",
      "         3.26969,   3.85726,   3.50648,   6.0629 ,   2.9628 ,   3.71766,\n",
      "         1.79714,   3.80848,   2.13984,   2.95643,   4.28963,   3.45376,\n",
      "         6.80953,   2.06221,   5.2219 ,   2.33704,   5.29463,   4.04506,\n",
      "         3.04081,   2.95202,   0.78715,   4.34781,   1.44925,   0.26624,\n",
      "        -3.6583 ,  -1.87616,   3.10666,   2.01634,   1.39176,   4.76057,\n",
      "         4.31387,   3.93304,   4.14982,   0.66722,   2.32193,   1.90408,\n",
      "         5.40393,   3.86274,   5.38433,   2.33153,   4.55623,   1.41661,\n",
      "         1.19151,   3.38851,   2.70715,   2.98503,   6.61675,   3.57214,\n",
      "         4.13206,   2.57348,   6.60602,   4.96335,   3.40094,   3.995  ,\n",
      "         3.68572,   5.00433,   6.38554,   3.74019,   3.32511,   5.26868,\n",
      "         6.50941,   1.44855,   7.2196 ,   0.40752,   2.38105,  -1.31335,\n",
      "         2.49024,  -1.60578,   1.09759,   3.33152,   2.44335,   1.62275,\n",
      "         0.49411,   2.10104,   3.52689,   6.59808,   4.61615,   2.26021,\n",
      "         3.08786,   3.77649,   4.06016,   4.41302,   1.96566,   3.12303,\n",
      "         2.21592,   5.34566,   1.03367,   0.59937,   3.42311,   1.20154,\n",
      "         2.43959,   2.29749,   2.50509,  -1.71071,   2.37465,  -2.10657,\n",
      "        -8.85337,  -4.56545,  -0.71524,   1.40231,   4.30045,   1.93332,\n",
      "         3.85174,   3.07251,   2.09495,  -0.94995,   2.69721,  -0.08926,\n",
      "         4.46716,   3.34038,   1.78137,   0.5757 ,   0.46229,   3.9269 ,\n",
      "         1.06912,   3.39116,   3.47186,  -1.38277,   5.13428,   4.83226,\n",
      "         2.01783,   3.58582,   2.46998,   1.59778,   0.73724,   2.31139,\n",
      "         1.28244,   2.82754,   2.21107,   1.94283,   2.23324,   3.14173,\n",
      "         4.48297,   3.24048,   2.11768,   2.48704,   0.56618,   2.16653,\n",
      "         3.30498,   4.50326,   2.55708,  -5.48895, -32.8791 ,  29.89166,\n",
      "         4.11961,   5.10931,   6.03326,   3.2443 ,   6.73015,  -1.99569,\n",
      "        -0.56549,   2.62584,   2.53365,   2.21935,   2.03928,   4.7472 ]), 'X_tilde': array([[-0.60800157, -1.39179907, -0.37670042, ...,  1.31756328,\n",
      "         1.10760184, -1.38044112],\n",
      "       [-0.44238384, -1.51913724,  0.30793826, ...,  2.7631645 ,\n",
      "         0.59630858, -0.37073024],\n",
      "       [-0.0887135 ,  0.18339862, -0.34210778, ..., -0.9591036 ,\n",
      "         0.54172414, -2.72972071],\n",
      "       ...,\n",
      "       [-2.51649855, -0.47471425, -2.62842862, ...,  2.27120835,\n",
      "         0.67846499, -0.27717866],\n",
      "       [-0.7712069 , -0.64768512,  2.71367121, ...,  4.26015672,\n",
      "        -1.33798006, -2.80561436],\n",
      "       [-0.99450877, -0.725138  , -2.19637   , ...,  3.46932807,\n",
      "        -0.24269991, -0.42339739]]), 'Y_lagged': array([], shape=(174, 0), dtype=float64)}\n"
     ]
    }
   ],
   "source": [
    "print(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = transformed_data['X_tilde']\n",
    "y = transformed_data['Y']\n",
    "\n",
    "# Split x and y into a 80/20 train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.60800157 -1.39179907 -0.37670042 ...  1.31756328  1.10760184\n",
      "  -1.38044112]\n",
      " [-0.44238384 -1.51913724  0.30793826 ...  2.7631645   0.59630858\n",
      "  -0.37073024]\n",
      " [-0.0887135   0.18339862 -0.34210778 ... -0.9591036   0.54172414\n",
      "  -2.72972071]\n",
      " ...\n",
      " [-2.51649855 -0.47471425 -2.62842862 ...  2.27120835  0.67846499\n",
      "  -0.27717866]\n",
      " [-0.7712069  -0.64768512  2.71367121 ...  4.26015672 -1.33798006\n",
      "  -2.80561436]\n",
      " [-0.99450877 -0.725138   -2.19637    ...  3.46932807 -0.24269991\n",
      "  -0.42339739]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -8.32783  -0.4757    7.39099   7.76189  -2.97534   4.76156  -4.38231\n",
      "  -6.26336   1.82056  -1.532     0.16      5.23673   9.00007   7.91695\n",
      "   8.25888   7.74372   6.85202   3.83757   3.26969   3.85726   3.50648\n",
      "   6.0629    2.9628    3.71766   1.79714   3.80848   2.13984   2.95643\n",
      "   4.28963   3.45376   6.80953   2.06221   5.2219    2.33704   5.29463\n",
      "   4.04506   3.04081   2.95202   0.78715   4.34781   1.44925   0.26624\n",
      "  -3.6583   -1.87616   3.10666   2.01634   1.39176   4.76057   4.31387\n",
      "   3.93304   4.14982   0.66722   2.32193   1.90408   5.40393   3.86274\n",
      "   5.38433   2.33153   4.55623   1.41661   1.19151   3.38851   2.70715\n",
      "   2.98503   6.61675   3.57214   4.13206   2.57348   6.60602   4.96335\n",
      "   3.40094   3.995     3.68572   5.00433   6.38554   3.74019   3.32511\n",
      "   5.26868   6.50941   1.44855   7.2196    0.40752   2.38105  -1.31335\n",
      "   2.49024  -1.60578   1.09759   3.33152   2.44335   1.62275   0.49411\n",
      "   2.10104   3.52689   6.59808   4.61615   2.26021   3.08786   3.77649\n",
      "   4.06016   4.41302   1.96566   3.12303   2.21592   5.34566   1.03367\n",
      "   0.59937   3.42311   1.20154   2.43959   2.29749   2.50509  -1.71071\n",
      "   2.37465  -2.10657  -8.85337  -4.56545  -0.71524   1.40231   4.30045\n",
      "   1.93332   3.85174   3.07251   2.09495  -0.94995   2.69721  -0.08926\n",
      "   4.46716   3.34038   1.78137   0.5757    0.46229   3.9269    1.06912\n",
      "   3.39116   3.47186  -1.38277   5.13428   4.83226   2.01783   3.58582\n",
      "   2.46998   1.59778   0.73724   2.31139   1.28244   2.82754   2.21107\n",
      "   1.94283   2.23324   3.14173   4.48297   3.24048   2.11768   2.48704\n",
      "   0.56618   2.16653   3.30498   4.50326   2.55708  -5.48895 -32.8791\n",
      "  29.89166   4.11961   5.10931   6.03326   3.2443    6.73015  -1.99569\n",
      "  -0.56549   2.62584   2.53365   2.21935   2.03928   4.7472 ]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sgLasso gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the sparse group LASSO module...\n"
     ]
    }
   ],
   "source": [
    "sgl.test_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import midasmlpy.sparse_group_lasso as sgl\n",
    "\n",
    "# Call the function\n",
    "model2 = sgl.best_model(x=X_train, y=y_train, group_size=degree, family='gaussian', nlam=100, pmax=122, intr=False, k_folds=3, disp_flag=True, alpha_values=11, alpha=None)\n",
    "\n",
    "print(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2['best_performance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_train\n",
    "y = y_train\n",
    "group_size = degree\n",
    "family = 'gaussian'\n",
    "nlam = 100\n",
    "pmax = 122\n",
    "intr = False\n",
    "k_folds = 3\n",
    "disp_flag = True\n",
    "alpha_values = 11\n",
    "alpha = None\n",
    "alsparse = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find model nlam number of models\n",
    "b0, beta, alam, npass, jerr, mse = sgl.sgLASSO_estimation(x, y, group_size, alsparse,family, pmax, intr)\n",
    "\n",
    "# Find mean performance for each lambda\n",
    "# Split the data into k_folds\n",
    "if family == 'binomial':\n",
    "    kf = sgl.StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "if family == 'gaussian':   \n",
    "    kf = sgl.KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# initialize performance list\n",
    "performance = []\n",
    "for train_index, test_index in kf.split(x,y):\n",
    "    # Based on the split, create the training and test data for this fold\n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    # Estimate the model on the training data\n",
    "    b0test, beta_test, alam, npass, jerr, mse_test = sgl.sgLASSO_estimation(x_train, y_train, group_size, alsparse, family, pmax=pmax, intr=intr, ulam=alam)\n",
    "    if family == 'gaussian':\n",
    "        performance.append(sgl.evaluate_gaussian(x_test, y_test, b0test, beta_test, intr=False, eval='mse'))\n",
    "    if family == 'binomial':\n",
    "        performance.append(sgl.evaluate_binomials(x_test, y_test, b0test, beta_test, intr=False, eval='auc', threshold=0.5))\n",
    "\n",
    "performance = np.array(performance)\n",
    "mean_performance = np.mean(performance, axis=0)\n",
    "if family == 'binomial':\n",
    "    best_lambda = np.argmax(mean_performance)\n",
    "if family == 'gaussian':\n",
    "    best_lambda = np.argmin(mean_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_performance[best_lambda]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmin(mean_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = transformed_data['X_tilde']\n",
    "y = transformed_data['Y']\n",
    "\n",
    "# # Split x and y into a 80/20 train test split\n",
    "train_size = int(0.8*x.shape[0])\n",
    "x_train, x_test = x[:train_size], x[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "b0, beta, alam, npass, jerr, mse = sgl.sgLASSO_estimation(x_train, y_train, group_size, alsparse,family, pmax, intr)\n",
    "evaluation_scores = [0] * len(b0)  # this will store evaluation scores\n",
    "for l in range(len(b0)):\n",
    "    predictions = np.dot(x_test, beta[:,l]) + b0[l]\n",
    "    evaluation_scores[l] = sgl.mean_squared_error(y_test, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(evaluation_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
